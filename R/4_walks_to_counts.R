##########################################
# RW trajectory sf data to count history #
##########################################

# This script takes the outputs generated by the RW_simulation.R script
# and the RW_raw_to_sf.R script as well as a desired sampling grid 
# (i.e. a grid grom the list of grids generated by the nphk_gridsize.R script).
#
# @ INPUT: List of grids 
# @ INPUT: List of true states (Slist)
# @ INPUT: List of population sizes N (Nlist)
# @ INPUT: Random walk trajectories (Wsf)
#          a. as shapefiles (.shp)
#          b. as tabular data (.rds) + binary geometries (.rds)
#
# It uses these inputs to generate a list of survey data/ information
# (i.e. count history, true state and observation probabilities)
# @ OUTPUT: lsurv
# 
# Optionally, it formats the count histories in a straightforward structure for 
# using it at the HPC clusters (VSC)
# @ OUTPUT: hpc.list
#
# Note: this script makes use of the build-in function foreach,
# which runs more efficiently on Linux! 

## 1. Intialize ----------------------------------------------------------------
# required R packages
library(dplyr)
library(data.table)
library(sf)
library(SDraw)
library(gdalUtils)
library(lubridate)
library(parallel)
library(doParallel)
source("R/functions.R")

memory.size(1*10^5)

# file directory
fdir <- "data/rw/"

# set situation
key <- 
  expand.grid(
    sim = 40,
    days = 25,
    hsteps = 6,
    r_hrc = c(F, T),
    hr_r = c(450, 900, 1800, 5400),
    speed = c("slow", "fast")
  )

key <- 
  key %>% mutate(
    hr_grid = case_when(
      hr_r == 450 ~ "g12",
      hr_r == 900 ~ "g6",
      hr_r == 1800 ~ "g3",
      hr_r == 5400 ~ "g2",
    ),
    Nmax = case_when(
      hr_r == 450 ~ 600,
      hr_r == 900 ~ 300,
      hr_r == 1800 ~ 150,
      hr_r == 5400 ~ 30,
    )
  ) %>% filter(r_hrc == F & hr_grid == "g12" | r_hrc == T)

# home range centre
hrc <- key$r_hrc

# home range radius
hr_r <- key$hr_r

# speed of movement
speed <- key$speed

# animal densities N
div <- sapply(1:nrow(key), function(x) switch(as.character(key$Nmax[x]), 
                                              "600" = 2, "300" = 2, 
                                              "150" = 3, "30" = 3))
Nmax <- unique(key$Nmax)
Nsteps <- sapply(1:nrow(key), function(x) 
  c(key$Nmax[x]*c(1,0.9,0.8), (key$Nmax[x]/div[x]) *c(1,0.9,0.8)))

# sampling percentage
samp_prc <- c(100, 50, 25)

# sampling grid
grid.list <- readRDS("data/grids.rds")
cam_grid <- grid.list[["g12"]]

# Use shapefiles (.shp), else use (.rds) files
shp <- F

# Genrate structured output list 
out.list <- list()

# Save splits for hpc clusters @VSC - either marked or unmarked counts
.split <- T; type <- "unmarked"

# Function to revert the list structure of a list of lists
revert_list <-  function(ll) {
  nms <- unique(unlist(lapply(ll, function(X) names(X))))
  ll <- lapply(ll, function(X) setNames(X[nms], nms))
  ll <- apply(do.call(rbind, ll), 2, as.list)
  lapply(ll, function(X) X[!sapply(X, is.null)])
}

## 2. Create sampling key -----------------------------------------------
# number of camera deployments to generate for each sampling percentage
ncams <- round((samp_prc/100) * nrow(cam_grid), 0)

# generate camera deployments for each sampling percentage
deploy.list <- 
  lapply(1:length(ncams), function(x) {
    sample_grid(grids.sf = cam_grid, n = ncams[x], 
                type = "regular", seed = 2030)
  })

# generate the 'field of view' for all cameras
fov <- get_circ_segement(deploy.list[[1]], r = 15, theta = 42)

# sites deployed for each sampling percentage
deploy.list <- 
  lapply(1:length(deploy.list), function(x) {
    deploy.list[[x]] %>% pull(site_id)
  })
names(deploy.list) <- samp_prc


## 3. Create lists of survey information ---------------------------------------
## Loop over all key
i<-1
for(i in 1:nrow(key)){
  
  # print progress in key
  print(paste0("situation: ", i, " out of ", nrow(key), " situations"))
  
  # load true states
  slist <-
    readRDS(paste0(fdir, "SList",
                   "_s", key$sim[i], 
                   "_N", key$Nmax[i],
                   "_d", key$days[i], 
                   "_hs", key$hsteps[i],  
                   "_hrr", key$hr_r[i], 
                   "_rhrc", key$r_hrc[i],
                   "_", key$speed[i],
                   ".rds"))
  
  # load list of N
  nlist <-
    readRDS(paste0(fdir, "NList",
                   "_s", key$sim[i], 
                   "_N", key$Nmax[i],
                   "_d", key$days[i], 
                   "_hs", key$hsteps[i],  
                   "_hrr", key$hr_r[i], 
                   "_rhrc", key$r_hrc[i],
                   "_", key$speed[i],
                   ".rds"))
  
  # load random walk data
  if(shp){
    
    # filename to load random walk sf data frame
    fn <- paste0("Wsf", "_hrr", key$hr_r[i], 
                 "_rhrc", key$r_hrc[i])
    
  } else {
    
    # random walk data without geometry column
    data <- 
      readRDS(paste0(fdir, "shapefiles/Wsf", 
                     "_hr", key$hr_grid[i], 
                     "_rhrc", key$r_hrc[i],
                     "_", key$speed[i],
                     ".rds"))
    
    # random walk geometries in binary encoding
    geoms <- 
      readRDS(paste0(fdir, "shapefiles/Wsf", 
                     "_hr", key$hr_grid[i], 
                     "_rhrc", key$r_hrc[i],
                     "_", key$speed[i],
                     "_geom.rds"))
    
    # index for each simulation_id
    rows <- c(0, sapply(1:40, function(x) max(which(data$sim_id == x))))
  }
  
  # initiate lists to store survey data
  lsurv <- list()
    
  ## Loop over all simulation instances
  for (s in 1:40) {
      
    # print progress in simulation instances
    print(paste0("simulation ", s, " out of ", key$sim[i], " simulations"))
      

    if(shp){
      # load sf data that satisfies the conditions in the SQL query
      rw <- st_read(paste0(fdir, "shapefiles/", fn, ".shp"), 
                    query = paste0('SELECT * FROM "', fn,  '" WHERE sim_id = ', i))
          
      # restore column names
      colnames(rw)[-ncol(rw)] <- c("sim_id", "day_id", "group_id", "hour_id",
                                       "step_id", "n", "hstep_length", "hstep_angle")
    } else {
      # recreate sf data from tabular data and binary geometries
      rw <- 
        st_as_sf(
          cbind(
            data[(rows[s]+1):rows[s+1],], 
            st_as_sfc(structure(geoms[(rows[s]+1):rows[s+1]], class = "WKB"))
          )
        )
    }
      
    # N's to iterate over
    n_mat <- nlist[[s]]
    
    # set up PSOCK clusters
    cl <- makeCluster(detectCores()-1, type = "PSOCK") 
    registerDoParallel(cl)
    
    # generate count/ detection data from walks  
    survey_info <- 
      #lapply(1:ncol(n_mat), function(x){
      foreach(x = 1:ncol(n_mat)) %dopar% {
              
        library(dplyr)
        library(sf)
        library(lubridate)
        source("R/functions.R")
        
        rw_n <- rw %>%
          arrange(group_id) %>%
          mutate(n = rep(n_mat[[x]], each = (6*24*25) - 5))
        
              
        list_survey_info(
          data.sf = rw_n,
          grid.sf = cam_grid,
          cam.sf = fov,
          deploy = deploy.list,
          true_states = slist[[s]][[x]],
          p = 1, r = 1
        )
      } 
      #})
   names(survey_info) <- colSums(n_mat)
        
   # stop PSOCK custers
   stopCluster(cl)
   
   # run garbage collector
   gc()

   # add to list
   lsurv[[s]] <- survey_info
  }
  
  ## Format list of count histories as follows:
  # 1st list level: 
  ## Home Range Area "nrow(key)" * Population Density "length(tmp)"
  # 2nd list level: 
  ## Sampling intensity (% of sites deployed)
  # 3rd list level:
  ## Simulation instances "nsim"

  input.list <- revert_list(lsurv)
  tmp.list <- list()
  
  for(j in 1:length(input.list)){
    tmp.list[[j]] <-
      revert_list(
        lapply(1:length(input.list[[j]]), function(k){
          out <-
            lapply(1:length(samp_prc), function(l){
              rows <- input.list[[j]][[k]]$sampled[[l]]
              list(
                counts = list(
                  unmarked = input.list[[j]][[k]]$count_hist$unmarked[rows, ],
                  marked = input.list[[j]][[k]]$count_hist$marked[rows, ]),
                psi = input.list[[j]][[k]]$psi,
                lambda = input.list[[j]][[k]]$lambda,
                p = input.list[[j]][[k]]$p[[l]],
                r = input.list[[j]][[k]]$r[[l]],
                r2 = input.list[[j]][[k]]$r2[[l]],
                mu = input.list[[j]][[k]]$mu[[l]]
              )
            })
            
          names(out) <- paste0("sampling_prc = ",
                               names(input.list[[j]][[k]]$sampled))
          return(out)
        })
      )
  }
  names(tmp.list) <- paste0("N = ", Nsteps[,i])
  out.list[[i]] <- tmp.list
}
names(out.list) <- paste0(paste0("rHRC = ", hrc), "_", 
                          paste0("HR_r = ", hr_r), "_", 
                          paste0("speed = ", speed))


# save survey info
saveRDS(out.list, paste0(fdir, "survey_infolist.rds"))

if(.split){
  for(i in 1:length(out.list)) {
    n1 <- names(out.list)[i]
      
    for(j in 1:length(out.list[[i]])){
      n2 <- names(out.list[[i]])[j]
        
      for(k in 1:length(out.list[[i]][[j]])){
        n3 <- names(out.list[[i]][[j]])[k]
          
        ll <- lapply(1:40, function(l) out.list[[i]][[j]][[k]][[l]]$counts[[type]])
        saveRDS(ll, paste0(fdir, "hpc/chlist_", n1, "_", n2, "_", n3, ".rds"))
      }
    }
  }
}
